# О проекте

Этот проект сосредоточен на контекстном переводе названий российских научных статей на английский язык. Путем fine-tuning'а модели ALMA 7B мы разработали инструмент, который обеспечивает точные и учитывающие контекст переводы, что позволяет сохранить нюансы и специфические термины научных работ. Модель развернута в виде бота в Telegram для легкой работы с ней.

# Важные файлы

1. Адаптер для модели: `checkpoint/train-alma`
2. Предсказания на нашей тестовой выборке (по которой мы считали метрики): `data/eval.xlsx`
3. **Предсказания на тестовой выборке от организаторов: `data/test_gen.xlsx`**

# Установка проекта

1. Установите в систему git, git lfs, poetry
2. Склонируйте репозиторий на свою машину
3. Установите в систему Python 3.11
4. Сделайте `poetry env use "путь/к/питону/3.11""`
5. Сделайте `poetry install`
6. **Важно: для обучения и запуска LLM потребуется GPU (подойдёт та, что есть в Google Colab). Локальные эксперименты делались на RTX 3090**

# Подготовка данных и обучение модели
**Важно: данный шаг можно пропустить! В репозитории уже есть обученный адаптер для модели и подготовленные данные**
1. `poetry run python -m tranhack.prepare_data` - запишет подготовленные датасеты в директории `data/train` и `data/test` (это будет тестовая выборка наша, по которой можно посчитать метрики)
2. `poetry run python -m tranhack.train_llm` - запустит обучение модели на подготовленных данных
3. Логи обучения можно посмотреть в tensorboard: `poetry run tensorboard --logdir logs`

# Как работать с обученной моделью

## Подготовка

1. Экспортируйте полную версию модели, наложив на неё обученный адаптер: `poetry run python -m tranhack.export_model --device cuda:0`. Этот шаг потребует некоторого времени, т.к. будет скачиваться модель ALMA, и в неё будет встраиваться наш обученный LORA-адаптер. В результате будет получена модель, которую уже можно куда-нибудь скопировать и запускать.

## Предсказания для нашей тестовой выборки и расчёт метрик

1. `poetry run python -m tranhack.generate_answers --mode eval`. В результате будет получен файл `data/eval.xlsx`, по которому можно посчитать метрики.
2. `poetry run python -m tranhack.compute_metrics`

## Предсказания для тестовой выборки от организаторов

1. `poetry run python -m tranhack.generate_answers --mode test`. В результате будет получен файл `data/test_gen.xlsx`, по которому организаторы смогут оценить качество работы модели.

## Запуск бота

1. `TG_TOKEN="ваш_тг_токен_для_бота" poetry run python -m tranhack.bot`

# Технологии и инструменты

* Python, PyTorch, PEFT, VLLM. 

# Команда

* Максим А, - LLM pipelines 
* Вадим Т. - data exploration
* Максим Ж. - domain exploration, TG bot development
* Саид А. - LLM pipelines, presentation

# Демо

![demo](data/img.png)

# Итог

Мы создали специализированный инструмент, который эффективно переводит названия русскоязычных научных статей на английский язык, сохраняя контекстную целостность. Развертывание модели как бота в Telegram обеспечивает легкий доступ к предоставляемой модели. Один из элементов дальнейших исследований - балансировка по темам и очистка обучающей выборки, внедрение Preference Optimization техник.

# Лицензия

См. LICENSE.txt