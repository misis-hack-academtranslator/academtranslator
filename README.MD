# Важные файлы

1. Адаптер для модели: `checkpoint/train-alma`
2. Предсказания на нашей тестовой выборке (по которой мы считали метрики): `data/eval.xlsx`
3. **Предсказания на тестовой выборке от организаторов: `data/test_gen.xlsx`**

# Установка проекта

1. Установите в систему git, git lfs, poetry
2. Склонируйте репозиторий на свою машину
3. Установите в систему Python 3.11
4. Сделайте `poetry env use "путь/к/питону/3.11""`
5. Сделайте `poetry install`
6. **Важно: для обучения и запуска LLM потребуется GPU (подойдёт та, что есть в Google Colab). Локальные эксперименты делались на RTX 3090**

# Подготовка данных и обучение модели
**Важно: данный шаг можно пропустить! В репозитории уже есть обученный адаптер для модели и подготовленные данные**
1. `poetry run python -m tranhack.prepare_data` - запишет подготовленные датасеты в директории `data/train` и `data/test` (это будет тестовая выборка наша, по которой можно посчитать метрики)
2. `poetry run python -m tranhack.train_llm` - запустит обучение модели на подготовленных данных
3. Логи обучения можно посмотреть в tensorboard: `poetry run tensorboard --logdir logs`

# Как работать с обученной моделью

## Подготовка

1. Экспортируйте полную версию модели, наложив на неё обученный адаптер: `poetry run python -m tranhack.export_model --device cuda:0`. Этот шаг потребует некоторого времени, т.к. будет скачиваться модель ALMA, и в неё будет встраиваться наш обученный LORA-адаптер. В результате будет получена модель, которую уже можно куда-нибудь скопировать и запускать.

## Предсказания для нашей тестовой выборки и расчёт метрик

1. `poetry run python -m tranhack.generate_answers --mode eval`. В результате будет получен файл `data/eval.xlsx`, по которому можно посчитать метрики.
2. `poetry run python -m tranhack.compute_metrics`

## Предсказания для тестовой выборки от организаторов

1. `poetry run python -m tranhack.generate_answers --mode test`. В результате будет получен файл `data/test_gen.xlsx`, по которому организаторы смогут оценить качество работы модели.
